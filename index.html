<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Beyond Geometric Context: Semantically Informed Robot Decision Making in the Open World">
  <meta name="keywords" content="SemNav">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Semantically Informed Robot Decision Making in the Open World</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Semantically Informed Robot Decision Making in the Open World</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://saumyasaxena.github.io/">Saumya Saxena</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=U3KSTwkAAAAJ&hl=en">Narunas Vaskevicius</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=7CLS0LwAAAAJ&hl=en">Jonathan Francis</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://palmieri.github.io/">Luigi Palmieri</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.oiermees.com/"> Oier Mees</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://cpaxton.github.io/about/">Chris Paxton</a><sup>4</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Bosch Research</span>
            <span class="author-block"><sup>2</sup>Carnegie Mellon University</span>
            <span class="author-block"><sup>3</sup>UC Berkeley</span>
            <span class="author-block"><sup>4</sup>FAIR, META AI</span>


          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent years have seen growing interest towards the development of semantics-aware embodied agents that are capable of performing generalizable behaviors in the real
            world. With recent advances in multimodal foundation models, several frameworks that incorporate semantic cues from diverse
            sensory inputs such as vision, language, and audio for robot decision making have been proposed. Deployment of such approaches in the real world faces several challenges such 
            as cross-domain generalization, adaptation to dynamic, human-shared environments and lifelong operation in open-world contexts. With the ambitious goal of addressing the aforementioned
            challenges, we propose the ICRA 2024 workshop “Semantically Informed Robot Decision Making in the Open World”. We aim to bring together researchers from different communities, such
            as computer vision, language, machine learning, and robotics, for enabling avenues of interdisciplinary research on methods that could facilitate the deployment of semantics-aware and
            generalizable embodied agents in unstructured and dynamic real world environments.
          </p>

          <h3 class="title is-3">Topics</h3>
          <p>
            Topics of the workshop include and are not limited to:
            <ul>
             <li> Representations for semantic-aware navigation and manipulation, in semi-static and dynamic environments.</li>
             <li> Considering different cues of dynamic environments (e.g., movements of humans, other vehicles, dynamic and mutable object states in the environment).</li>
             <li> Representations for handling open-vocabulary scene context, focused on real-world application.</li>
             <li> Semantically-rich representations from multiple input modalities, e.g., language, vision, audio, end-effector haptics, joint torque, IMU signals, etc.</li>
             <li> Methods for enabling policy transfer, domain adaptation, generalization, and robustness.</li>
             <li> Semantics-awareness for Robot Learning—applications on real robots, with open-world challenges.</li>
             <li> Semantics-aware motion planning and control in dynamic environments.</li>
             <li> Semantics-aware decision-making (e.g., reinforcement learning, task and behavior planning).      </li>
            </ul> 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Concurrent Work. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Supported by</h2>

        <div class="content has-text-justified">
          <p>
            Our workshop is supported by the following IEEE RAS Technical Committee (TC)

            <ul>
              <li> <a href="https://www.ieee-ras.org/computer-robot-vision">TC on Computer and Robot Vision</a></li>              
            </ul> 

          </p>
  
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Based on the following <a href="https://github.com/nerfies/nerfies.github.io"> nerfies web page</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
</body>
</html>