<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Beyond Geometric Context: Semantically Informed Robot Decision Making in the Open World">
  <meta name="keywords" content="SemNav">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Semantically Informed Robot Decision Making in the Open World</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Semantically Informed Robot Decision Making in the Open World</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://saumyasaxena.github.io/">Saumya Saxena</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=U3KSTwkAAAAJ&hl=en">Narunas Vaskevicius</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=7CLS0LwAAAAJ&hl=en">Jonathan Francis</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://palmieri.github.io/">Luigi Palmieri</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.oiermees.com/"> Oier Mees</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://cpaxton.github.io/about/">Chris Paxton</a><sup>4</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Bosch Research</span>
            <span class="author-block"><sup>2</sup>Carnegie Mellon University</span>
            <span class="author-block"><sup>3</sup>UC Berkeley</span>
            <span class="author-block"><sup>4</sup>FAIR, META AI</span>


          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In the recent years, there has been significant interest towards developing 
            embodied agents that can perform generalizable and semantics-aware behaviors 
            in the real world. With the surge of large language and foundation models, 
            several research groups from the robotics, computer vision and machine learning
             communities have presented methods that allow the generation of robot behaviors 
             which consider semantic cues extracted from multi-modal sensor inputs (e.g. video, audio, text).
             However, those methods often struggle to generalize across domains and to achieve lifelong robot operations in the open-world contexts. 
          </p>
          <p>
            The goal of our workshop is to bring together researchers from computer vision, language, machine learning, and robotics 
            to share and discuss the latest advances in embodied intelligent agents, with a particular focus
             on the deployment on real robots working in dynamic environments. 
          </p>

          <h3 class="title is-3">Topics</h3>
          <p>
            Topics of the workshop include and are not limited to:
            <ul>
             <li> Representations for semantic-aware navigation and manipulation, in semi-static and dynamic environments.</li>
             <li> Considering different cues of dynamic environments (e.g., movements of humans, other vehicles, dynamic and mutable object states in the environment).</li>
             <li> Representations for handling open-vocabulary scene context, focused on real-world application.</li>
             <li> Semantically-rich representations from multiple input modalities, e.g., language, vision, audio, end-effector haptics, joint torque, IMU signals, etc.</li>
             <li> Methods for enabling policy transfer, domain adaptation, generalization, and robustness.</li>
             <li> Semantics-awareness for Robot Learningâ€”applications on real robots, with open-world challenges.</li>
             <li> Semantics-aware motion planning and control in dynamic environments.</li>
             <li> Semantics-aware decision-making (e.g., reinforcement learning, task and behavior planning).      </li>
            </ul> 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Concurrent Work. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Supported by</h2>

        <div class="content has-text-justified">
          <p>
            Our workshop is supported by the following IEEE RAS Technical Committee (TC)

            <ul>
              <li> <a href="https://www.ieee-ras.org/robot-learning">TC on Robot Learning</a>  </li>
              <li> <a href="https://www.ieee-ras.org/computer-robot-vision">TC on Computer and Robot Vision</a></li>
              
            </ul> 

          </p>
  
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Based on the following <a href="https://github.com/nerfies/nerfies.github.io"> nerfies web page</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
</body>
</html>